<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Wynn - Homepage</title>

    <meta name="author" content="Nan Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üÄÅ</text></svg>" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <!-- ÂõæÊ†áÂ≠ó‰ΩìÂ∫ì - ‰ΩøÁî®Êõ¥ËΩªÈáèÁöÑÁâàÊú¨ -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" media="print" onload="this.media='all'">
    <noscript><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"></noscript>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css" media="print" onload="this.media='all'">
    <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css"></noscript>
    <style type="text/css">
        /* ÂÜÖËÅîÊ†∑ÂºèÂ∑≤ÁßªËá≥Â§ñÈÉ®CSSÊñá‰ª∂Ôºå‰øùÊåÅÁÆÄÊ¥Å */
        .newnew {
            background: var(--blue-accent);
            color: white;
            font-weight: 600;
            padding: 3px 8px;
            border-radius: var(--radius-sm);
            font-size: 0.8em;
            letter-spacing: 0.02em;
        }
      </style>
    <script src="scripts/functions.js"></script>
  </head>

  <body>
    <!-- ‰∏ªÈ¢òÂàáÊç¢ÊåâÈíÆ -->
    <div class="theme-toggle-container">
      <button id="theme-toggle" class="theme-toggle-btn" aria-label="ÂàáÊç¢‰∏ªÈ¢ò">
        <span class="theme-icon sun-icon">‚òÄÔ∏è</span>
        <span class="theme-icon moon-icon">üåô</span>
      </button>
    </div>
    
    <div class="main-container">
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>üÄÅ Nan Wang&nbsp;&nbsp;&nbsp;</name>
              </p>
                <p>
    I am an Algorithm Engineer at the <strong><a href="https://www.baai.ac.cn/">Beijing Academy of Artificial Intelligence (BAAI)</a></strong>, where I develop and implement cutting-edge solutions in neural rendering and world models, exploring their potential applications in VR, robotics, and autonomous driving. I earned my Master's in Computer Science from the <strong><a href="https://see.tongji.edu.cn/index.htm">Tongji University</a></strong>.

                <div class="contact-icons">
                <a href="mailto:bigcileng@gmail.com" class="contact-icon email-icon">
                  <i class="fas fa-envelope"></i>
                  <span>Email</span>
                </a>
                <a href="https://scholar.google.com/citations?user=BWfLE6EAAAAJ" class="contact-icon scholar-icon">
                  <i class="fas fa-graduation-cap"></i>
                  <span>Scholar</span>
                </a>
                <a href="https://github.com/BigCiLeng/" class="contact-icon github-icon">
                  <i class="fab fa-github"></i>
                  <span>GitHub</span>
                </a>
                <a href="https://x.com/bigcileng" class="contact-icon twitter-icon">
                  <i class="fab fa-twitter"></i>
                  <span>Twitter</span>
                </a>
                </div>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="https://github.com/BigCiLeng"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/ava_freedom1.jpg" class="hoverZoomLink" loading="lazy"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>News</h2>
          <div class="news">
            <ul style="text-align:justify;height: 150px;">
              <li><strong class="newnew">[09-2025]</strong> Our HOLO is is accepted to WACV 2026.</a></li>
              <li><strong class="newnew">[08-2025]</strong> Our <a href="https://gzwsama.github.io/OnePoseviaGen.github.io/">OnePoseviaGen</a> is accepted to CoRL 2025 as <strong>Oral.</strong></li>
              <li><strong class="newnew">[06-2025]</strong> Our <a href="https://bigcileng.github.io/bilateral-driving/">BilateralDriving</a> is now available.</li>
              <li><strong class="newnew">[02-2025]</strong> I have been on an internship at <a href="https://www.baai.ac.cn/">Beijing Academy of Artificial Intelligence</a>. </li>
              <li><strong class="newnew">[02-2025]</strong> Two papers are accepted to ICRA 2025. </li>
              <li><strong class="newnew">[01-2025]</strong> One paper was accepted to ICASSP 2025. </li>
              <li><strong>[10-2024]</strong> I have been on an internship at <a href="https://www.noematrix.ai/">Shanghai Noematrix Intelligence Technology Ltd</a>. </li>
              <li><strong>[05-2024]</strong> I have been on an internship at <a href="https://www.mi.com/cyberone">Xiaomi Robot Technology</a>. </li>
              <li><strong>[03-2024]</strong> I have been on an internship at <a href="https://www.megvii.com/">Megvii</a>. </li>
            </ul>
          </div>
          </td>
        </tr>
      </tbody></table>



          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
            Representative papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 8px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <!-- holo -->
      <tr onmouseout="holo_start()" onmouseover="holo_stop()">
        <td style="padding:12px;width:18%;vertical-align:top">
          <div class="one">
            <div class="two" id='holo_img'><video width=100% height=100% muted autoplay loop>
            <source src="research/holo-demo/holo.png" type="video/png">
            Your browser does not support the video tag.
            </video></div>
            <img src="research/holo-demo/holo.png" width="160" loading="lazy">
          </div>
          <script type="text/javascript">
            function holo_start() {
              document.getElementById('holo_img').style.opacity = "1";
            }

            function holo_stop() {
              document.getElementById('holo_img').style.opacity = "0";
            }
            holo_stop()
          </script>
        </td>
        <td style="padding:12px;width:82%;vertical-align:top">
          <papertitle>HOLO: Holistic Lightweight Optimization for Scene Understanding with Auto-Annotation and Multimodal Learning</papertitle>
          <br>
            Xiaoyun hu*, 
            <a href="https://scholar.google.com/citations?user=BWfLE6EAAAAJ">Xiaohan Yan*</a>,
            <strong>Nan Wang</strong>,
            <a href="https://kevinsong729.github.io/">Xiaowei Song</a>,
            Gang Wei, 
            Zhicheng Wang
          <br>
            <strong><em>WACV, 2026</em></strong>
          <br>
            <div class="paper-links">
              <!-- <a href="https://ieeexplore.ieee.org/document/10887567" class="paper-icon paper-icon" title="Paper">
                <i class="fas fa-file-pdf"></i>
                <span>Paper</span>
              </a>
              <a href="https://github.com/BigCiLeng/SGGS" class="paper-icon code-icon" title="Code">
                <i class="fab fa-github"></i>
                <span>Code</span>
              </a>
              <a href="research/SGGS-Poster.pdf" class="paper-icon poster-icon" title="Poster">
                <i class="fas fa-image"></i>
                <span>Poster</span>
              </a> -->
            </div>
          <p style="margin:2px 0;line-height:1.4;"> 
            We propose HOLO, which includes a large-scale scene description dataset and a lightweight 3D-LLM.
          </p>
        </td>
      </tr>

      <!-- oneposeviagen -->
      <tr onmouseout="oneposeviagen_start()" onmouseover="oneposeviagen_stop()">
        <td style="padding:12px;width:18%;vertical-align:top">
          <div class="one">
            <div class="two" id='oneposeviagen_img'><video width=100% height=100% muted autoplay loop>
            <source src="research/oneposeviagen/oneposeviagen-demo.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src="research/oneposeviagen/oneposeviagen-demo.png" width="160" loading="lazy">
          </div>
          <script type="text/javascript">
            function oneposeviagen_start() {
              document.getElementById('oneposeviagen_img').style.opacity = "1";
            }

            function oneposeviagen_stop() {
              document.getElementById('oneposeviagen_img').style.opacity = "0";
            }
            oneposeviagen_stop()
          </script>
        </td>
        <td style="padding:12px;width:82%;vertical-align:top">
          <papertitle>One View, Many Worlds: Single-Image to 3D Object Meets Generative Domain Randomization for One-Shot 6D Pose Estimation</papertitle>
          <br>
            <a href="https://github.com/GZWSAMA">Zheng Geng</a>,
            <strong>Nan Wang</strong>,
            <a href="https://daniellli.github.io/">Shaocong Xu</a>,
            <a href="https://github.com/hugoycj">Chongjie Ye</a>,
            <a href="https://scholar.google.com/citations?user=V-YdQiAAAAAJ">Bohan Li</a>,
            <a href="https://scholar.google.com/citations?user=HsV0WbwAAAAJ">Zhaoxi Chen</a>,
            <a href="https://pengsida.net/">Sida Peng</a>,
            <a href="https://scholar.google.com.hk/citations?user=ygQznUQAAAAJ&amp;hl=en">Hao Zhao</a>
          <br>
            <strong><em>arXiv, 2025</em></strong>
          <br>
            <div class="paper-links">
              <a href="https://gzwsama.github.io/OnePoseviaGen.github.io/" class="paper-icon project-icon">
                <i class="fas fa-globe"></i>
                <span>Project</span>
              </a>
              <a href="https://arxiv.org/abs/2509.07978" class="paper-icon arxiv-icon">
                <i class="ai ai-arxiv"></i>
                <span>Paper</span>
              </a>
              <a href="https://github.com/GZWSAMA/OnePoseviaGen/tree/main" class="paper-icon code-icon">
                <i class="fab fa-github"></i>
                <span>Code</span>
              </a>
            </div>
          <p style="margin:2px 0;line-height:1.4;"> 
            We use Multi-Scale Bilateral Grids that improves geometric accuracy in driving scene reconstruction through enhancing photometric consistency.
          </p >
        </td>
      </tr>

      <!-- bilateraldriving -->
      <tr onmouseout="bilateraldriving_start()" onmouseover="bilateraldriving_stop()">
        <td style="padding:12px;width:18%;vertical-align:top">
          <div class="one">
            <div class="two" id='bilateraldriving_img'><video width=100% height=100% muted autoplay loop>
            <source src="research/bilateraldriving-demo/bilateraldriving-demo.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src="research/bilateraldriving-demo/bilateraldriving-demo-cover.jpg" width="160" loading="lazy">
          </div>
          <script type="text/javascript">
            function bilateraldriving_start() {
              document.getElementById('bilateraldriving_img').style.opacity = "1";
            }

            function bilateraldriving_stop() {
              document.getElementById('bilateraldriving_img').style.opacity = "0";
            }
            bilateraldriving_stop()
          </script>
        </td>
        <td style="padding:12px;width:82%;vertical-align:top">
          <papertitle>Unifying Appearance Codes and Bilateral Grids for Driving Scene Gaussian Splatting</papertitle>
          <br>
            <strong>Nan Wang</strong>,
            <a href="https://tao-11-chen.github.io/">Yuantao Chen</a>,
            <a href="https://li-xingxiao.github.io/homepage/">Lixing Xiao</a>,
            <a href="https://scholar.google.com.hk/citations?user=v0iwkScAAAAJ&amp;hl=en&amp;oi=sra">Weiqing Xiao</a>,
            <a href="https://scholar.google.com/citations?user=V-YdQiAAAAAJ">Bohan Li</a>,
            <a href="https://scholar.google.com/citations?user=HsV0WbwAAAAJ">Zhaoxi Chen</a>,
            <a href="https://github.com/hugoycj">Chongjie Ye</a>,
            <a href="https://daniellli.github.io/">Shaocong Xu</a>,
            <a href="https://scholar.google.com/citations?user=P4efBMcAAAAJ">Saining Zhang</a>,
            <a href="https://ziyangyan.github.io/">Ziyang Yan</a>,
            <a href="https://scholar.google.com.hk/citations?user=NMSccqAAAAAJ">Pierre Merriaux</a>,
            <a href="">Lei Lei</a>,
            <a href="https://tianfan.info/">Tianfan Xue</a>,
            <a href="https://scholar.google.com.hk/citations?user=ygQznUQAAAAJ&amp;hl=en">Hao Zhao</a>
          <br>
            <strong><em>arXiv, 2025</em></strong>
          <br>
            <div class="paper-links">
              <a href="https://bigcileng.github.io/bilateral-driving/" class="paper-icon project-icon">
                <i class="fas fa-globe"></i>
                <span>Project</span>
              </a>
              <a href="https://arxiv.org/abs/2506.05280" class="paper-icon arxiv-icon">
                <i class="ai ai-arxiv"></i>
                <span>Paper</span>
              </a>
              <a href="https://github.com/BigCiLeng/bilateral-driving" class="paper-icon code-icon">
                <i class="fab fa-github"></i>
                <span>Code</span>
              </a>
            </div>
          <p style="margin:2px 0;line-height:1.4;"> 
            We use Multi-Scale Bilateral Grids that improves geometric accuracy in driving scene reconstruction through enhancing photometric consistency.
          </p >
        </td>
      </tr>

      <tr onmouseout="pugs_start()" onmouseover="pugs_stop()">
        <td style="padding:12px;width:18%;vertical-align:top">
          <div class="one">
            <div class="two" id='pugs_img'><video width=100% muted autoplay loop>
            <source src="research/pugs-demo/pugs-demo.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src="research/pugs-demo/pugs-demo-cover.jpg" width=160 loading="lazy">
          </div>
          <script type="text/javascript">
            function pugs_start() {
              document.getElementById('pugs_img').style.opacity = "1";
            }

            function pugs_stop() {
              document.getElementById('pugs_img').style.opacity = "0";
            }
            pugs_stop()
          </script>
        </td>
        <td style="padding:12px;width:82%;vertical-align:top">
          <papertitle>PUGS: Zero-shot Physical Understanding with Gaussian Splatting</papertitle>
          <br>
            <a href="https://github.com/EverNorif">Yinghao Shuai</a>,
            <a href="https://marcyu0303.github.io/">Ran Yu</a>,
            <a href="https://tao-11-chen.github.io/">Yuantao Chen</a>,
            Zijian Jiang,
            <a href="https://kevinsong729.github.io/">Xiaowei Song</a>,
            <strong>Nan Wang</strong>,
            Jv Zheng,
            Jianzhu Ma,
            Meng Yang,
            Zhicheng Wang,
            Wenbo Ding,
            <a href="https://sites.google.com/view/fromandto">Hao Zhao</a>
          <br>
            <strong><em>ICRA, 2025</em></strong>
          <br>
            <div class="paper-links">
              <a href="https://evernorif.github.io/PUGS/" class="paper-icon project-icon" title="Project Page">
                <i class="fas fa-globe"></i>
                <span>Project</span>
              </a>
              <a href="https://arxiv.org/abs/2502.12231" class="paper-icon arxiv-icon" title="Paper">
                <i class="ai ai-arxiv"></i>
                <span>Paper</span>
              </a>
              <a href="https://github.com/EverNorif/PUGS" class="paper-icon code-icon" title="Code">
                <i class="fab fa-github"></i>
                <span>Code</span>
              </a>
            </div>
          <p style="margin:2px 0;line-height:1.4;"> 
            We reconstruct 3D objects using the Gaussian splatting representation and predicts various physical properties in a zero-shot manner. 
          </p >
        </td>
      </tr>

      <tr onmouseout="re0_start()" onmouseover="re0_stop()">
        <td style="padding:12px;width:18%;vertical-align:top">
          <div class="one">
            <img src="research/re0-demo/re0-cover.png" width="160" loading="lazy">
          </div>
        </td>
        <td style="padding:12px;width:82%;vertical-align:top">
          <papertitle>RE0: Recognize Everything with 3D Zero-shot Open-Vocabulary Instance Segmentation</papertitle>
          <br>
            <a href="https://micro-han.github.io/">Xiaohan Yan</a>,
            Zijian Jiang,
            <a href="https://github.com/EverNorif">Yinghao Shuai</a>,
            <strong>Nan Wang</strong>,
            <a href="https://kevinsong729.github.io/">Xiaowei Song</a>,
            <a href="https://fusheng-ji.github.io/">Wenbo Ji</a>,
            Ge Wu,
            <a href="https://github.com/dragonbra">Jinyu He</a>,
            Gang Wei,
            Zhicheng Wang
          <br>
            <strong><em>ICRA, 2025</em></strong>
          <br>
            <div class="paper-links">
              <a href="https://recognizeeverything.github.io/" class="paper-icon project-icon" title="Project Page">
                <i class="fas fa-globe"></i>
                <span>Project</span>
              </a>
              <a href="https://recognizeeverything.github.io/src/RE0_for_NeurIPS_2024.pdf" class="paper-icon paper-icon" title="Paper">
                <i class="fas fa-file-pdf"></i>
                <span>Paper</span>
              </a>
              <a href="https://github.com/RecognizeEverything/Re0" class="paper-icon code-icon" title="Code">
                <i class="fab fa-github"></i>
                <span>Code</span>
              </a>
            </div>
          <p style="margin:2px 0;line-height:1.4;"> 
            We leverage the 3D geometry information and the semantic features to address the challenge of 3D instance segmentation. 
          </p >
        </td>
      </tr>

      <tr onmouseout="sggs_start()" onmouseover="sggs_stop()">
        <td style="padding:12px;width:18%;vertical-align:top">
          <div class="one">
            <div class="two" id='sggs_img'><video width=100% height=100% muted autoplay loop>
            <source src="research/sggs-demo/sggs1.png" type="video/png">
            Your browser does not support the video tag.
            </video></div>
            <img src="research/sggs-demo/sggs1.png" width="160" loading="lazy">
          </div>
          <script type="text/javascript">
            function sggs_start() {
              document.getElementById('sggs_img').style.opacity = "1";
            }

            function sggs_stop() {
              document.getElementById('sggs_img').style.opacity = "0";
            }
            sggs_stop()
          </script>
        </td>
        <td style="padding:12px;width:82%;vertical-align:top">
          <papertitle>Semantic-Guided Gaussian Splatting
            with Deferred Rendering</papertitle>
          <br>
            <strong>Nan Wang</strong>,
            <a href="https://micro-han.github.io/">Xiaohan Yan</a>,
            <a href="https://kevinsong729.github.io/">Xiaowei Song</a>,
            Zhicheng Wang
          <br>
            <strong><em>ICASSP, 2025</em></strong>
          <br>
            <div class="paper-links">
              <a href="https://ieeexplore.ieee.org/document/10887567" class="paper-icon paper-icon" title="Paper">
                <i class="fas fa-file-pdf"></i>
                <span>Paper</span>
              </a>
              <a href="https://github.com/BigCiLeng/SGGS" class="paper-icon code-icon" title="Code">
                <i class="fab fa-github"></i>
                <span>Code</span>
              </a>
              <a href="research/SGGS-Poster.pdf" class="paper-icon poster-icon" title="Poster">
                <i class="fas fa-image"></i>
                <span>Poster</span>
              </a>
            </div>
          <p style="margin:2px 0;line-height:1.4;"> 
            We use semantic features derived from 2D foundation model to revolutionize the material property optimization for 3DGS.
          </p>
        </td>
      </tr>

      <tr onmouseout="icic_start()" onmouseover="icic_stop()">
        <td style="padding:12px;width:18%;vertical-align:top">
          <div class="one">
            <div class="two" id='icic_img'><video width=100% muted autoplay loop>
            <source src="research/icic-demo/ICIC.jpg" type="video/png">
            Your browser does not support the video tag.
            </video></div>
            <img src="research/icic-demo/ICIC.jpg" width="160" loading="lazy">
          </div>
          <script type="text/javascript">
            function icic_start() {
              document.getElementById('icic_img').style.opacity = "1";
            }
            function icic_stop() {
              document.getElementById('icic_img').style.opacity = "0";
            }
            icic_stop()
          </script>
        </td>
        <td style="padding:12px;width:82%;vertical-align:top">
          <papertitle>GreedyAgent: A Simple yet Efficient Approach for Meta learning from Learning Curves</papertitle>
          <br>
            <a href="https://github.com/dragonbra">Jinyu He</a>,
            <a href="https://kevinsong729.github.io/">Xiaowei Song</a>,
            <a href="https://micro-han.github.io/">Xiaohan Yan</a>,
            <strong>Nan Wang</strong>,
            Yuqi Miao, 
            Zijian Jiang, 
            Fei Chao, 
            Yan Zhang, 
            Shengchuan Zhang, 
            Rongrong Ji
          <br>
            <strong><em>ICIC, 2024, oral</em></strong>
          <br>
            <div class="paper-links">
              <a href="https://dl.acm.org/doi/10.1007/978-981-97-5663-6_41" class="paper-icon paper-icon" title="Paper">
                <i class="fas fa-file-pdf"></i>
                <span>Paper</span>
              </a>
              <a href="https://github.com/dragonbra/MetaLC-2nd-Round" class="paper-icon code-icon" title="Code">
                <i class="fab fa-github"></i>
                <span>Code</span>
              </a>
            </div>
          <p style="margin:2px 0;line-height:1.4;"> 
            A key sub-problem: meta-learning from learning curves is an mature but gradually attention area within the field of meta-learning.
          </p>
        </td>
      </tr>

      <tr onmouseout="prcv_start()" onmouseover="prcv_stop()">
        <td style="padding:12px;width:18%;vertical-align:top">
          <div class="one">
            <div class="two" id='prcv_img'><video width=100% height=100% muted autoplay loop>
            <source src="research/prcv/PRCV.png" type="video/png">
            Your browser does not support the video tag.
            </video></div>
            <img src="research/prcv/PRCV.png" width="160" loading="lazy">
          </div>
          <script type="text/javascript">
            function prcv_start() {
              document.getElementById('prcv_img').style.opacity = "1";
            }
            function prcv_stop() {
              document.getElementById('prcv_img').style.opacity = "0";
            }
            prcv_stop()
          </script>
        </td>
        <td style="padding:12px;width:82%;vertical-align:top">
          <papertitle>AttenPoint: Exploring Point Cloud Segmentation through Attention-Based Modules</papertitle>
          <br>
            <a href="https://micro-han.github.io/">Xiaohan Yan</a>,
            <strong>Nan Wang</strong>,
            <a href="https://kevinsong729.github.io/">Xiaowei Song</a>,
            Gang Wei, 
            Zhicheng Wang
          <br>
            <strong><em>PRCV, 2024</em></strong>
          <br> 
            <div class="paper-links">
              <a href="https://dl.acm.org/doi/10.1007/978-981-97-8508-7_11" class="paper-icon paper-icon" title="Paper">
                <i class="fas fa-file-pdf"></i>
                <span>Paper</span>
              </a>
            </div>
          <p style="margin:2px 0;line-height:1.4;"> 
            We combine local and global features of the structures and performance to perform few-shot point cloud semantic segmentation.  
          </p>
          </td>
      </tr>
    </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Projects</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 8px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <!-- r2s pipeline -->
      <tr onmouseout="r2s_stop()" onmouseover="r2s_start()" bgcolor="#ffffd0"> 
        <td style="padding:12px;width:18%;vertical-align:top">
          <div class="one">
            <div class="two" id='r2s_image'><video width=100% muted autoplay loop>
            <source src="research/r2g-demo/r2g-demo.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='research/r2g-demo/r2g-demo-cover.jpg' width=100%>
          </div>
          <script type="text/javascript">
            function r2s_start() {
              document.getElementById('r2s_image').style.opacity = "1";
            }

            function r2s_stop() {
              document.getElementById('r2s_image').style.opacity = "0";
            }
            r2s_stop()
          </script>
        </td>
        <td style="padding:12px;width:82%;vertical-align:top">
          <papertitle>A Real2Sim Pipeline for robotics simulation</papertitle>
          <br>
            <em>Xiaomi</em>
          <br>
            <strong><em>2024-06</em></strong>
          <br>
            <div class="paper-links">
              <a href="https://github.com/BigCiLeng/R2G" class="paper-icon code-icon" title="Code">
                <i class="fab fa-github"></i>
                <span>Code</span>
              </a>
            </div>
          <p style="margin:2px 0;line-height:1.4;">
            We use 3D Gaussain Splating to build a novel robotics simulator, the physical simulation is implemented by ISAAC SIM while the photorealistic render is implemented by 3DGS.
          </p>
        </td>
      </tr>

      <!-- assistgs -->
      <tr onmouseout="assistgs_stop()" onmouseover="assistgs_start()">
        <td style="padding:12px;width:18%;vertical-align:top">
          <div class="one">
            <div class="two" id='assistgs_image'><video width=100% muted autoplay loop>
            <source src="research/assist-demo/assist-demo.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='research/assist-demo/assist-demo-cover.jpg' width=100%>
          </div>
          <script type="text/javascript">
            function assistgs_start() {
              document.getElementById('assistgs_image').style.opacity = "1";
            }

            function assistgs_stop() {
              document.getElementById('assistgs_image').style.opacity = "0";
            }
            assistgs_stop()
          </script>
        </td>
        <td style="padding:12px;width:82%;vertical-align:top">
          <papertitle>3DGS implementation for Structured-NeRF: Hierarchical Scene Graph with Neural Representation</papertitle>
          <br>
            <em>DISCOVER Robotics</em>
          <br>
            <strong><em>2023-11</em></strong>
          <br>
            <div class="paper-links">
              <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05154.pdf" class="paper-icon paper-icon" title="Paper">
                <i class="fas fa-file-pdf"></i>
                <span>Paper</span>
              </a>
              <a href="https://github.com/BigCiLeng/assist-gs" class="paper-icon code-icon" title="Code">
                <i class="fab fa-github"></i>
                <span>Code</span>
              </a>
            </div>
          <p style="margin:2px 0;line-height:1.4;">
            I use 3D Gaussian Splatting and nerfstudio to build an implementation, 
            which can accomplish the 3D scene decomposition and Reconstruction.
          </p>
        </td>
      </tr>

      <!-- randla-randlasqn -->
      <tr onmouseout="randla_stop()" onmouseover="randla_stop()">
          <td style="padding:12px;width:18%;vertical-align:top">
              <div class="one">
              <div class="two" id='randla_image'><video  width=100% muted autoplay loop>
              <source src="research/other/randla.png" type="video/png">
              Your browser does not support the video tag.
              </video></div>
              <img src='research/other/randla.png' width=100%>
              </div>
              <script type="text/javascript">
              function randla_start() {
                  document.getElementById('randla_image').style.opacity = "1";
              }

              function randla_stop() {
                  document.getElementById('randla_image').style.opacity = "0";
              }
              randla_stop()
              </script>
          </td>
          <td style="padding:12px;width:82%;vertical-align:top">
              <papertitle>Pytorch-Lightning Implementation of RandLA-Net && SQN</papertitle>
              <br>
                <strong><em>2023-10</em></strong>
              <br>
              <div class="paper-links">
                <a href="https://github.com/BigCiLeng/RandLA_pl" class="paper-icon code-icon" title="RandLA Code">
                  <i class="fab fa-github"></i>
                  <span>RandLA</span>
                </a>
                <a href="https://github.com/BigCiLeng/SQN_pl" class="paper-icon code-icon" title="SQN Code">
                  <i class="fab fa-github"></i>
                  <span>SQN</span>
                </a>
              </div>
              <p></p>
              <p style="margin:2px 0;line-height:1.4;">
              <a href="https://arxiv.org/abs/1911.11236">RandLA-Net</a> (CVPR2020) is a light net which can process efficient semantic segmentation for 3D point clouds,
              and <a href="https://arxiv.org/abs/2104.04891">SQN</a> (ECCV2022) achieves promising performance on seven large-scale open datasets under weak supervision schemes.
              </p>
          </td>
      </tr>

      <!-- STEM EXAM -->
      <tr onmouseout="stemExam_stop()" onmouseover="stemExam_stop()" >
          <td style="padding:12px;width:18%;vertical-align:top">
              <div class="one">
              <a href="research/other/rag.png"><img src='research/other/rag.png' width=100%></a>
              </div>
              <script type="text/javascript">
              function stemExam_start() {
                  document.getElementById('stemExam_image').style.opacity = "1";
              }

              function stemExam_stop() {
                  document.getElementById('stemExam_image').style.opacity = "0";
              }
              stemExam_stop()
              </script>
          </td>
          <td style="padding:12px;width:82%;vertical-align:top">
              <papertitle>LLM Science Exam - Use LLMs to answer difficult science questions</papertitle>
              <br>
                <strong>Nan Wang</strong>,
                <a href="https://micro-han.github.io/">Xiaohan Yan</a>,
                <a href="https://kevinsong729.github.io/">Xiaowei Song</a>
              <br>
                <strong><em>Kaggle, 2023-10</em></strong>
              <br>
                <div class="paper-links">
                  <a href="https://github.com/490CAD/LLM4Science" class="paper-icon code-icon" title="Code">
                    <i class="fab fa-github"></i>
                    <span>Code</span>
                  </a>
                </div>
              <p style="margin:2px 0;line-height:1.4;">
                LLM4Science ü•à silver medal solution. We make it into a RAG (Retrieval Augmented Generation) task and finetune three Deberta models with different finetuning and combine their output features to infer the right answer. 
              </p>
          </td>
      </tr>

    </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Short Bio</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 8px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <!-- write Bio here -->
      <tr>
        <td style=padding:00px;width:22%;vertical-align:middle;padding-left:20px>
          <!-- HTML !-->
          I am a M.Sc student in Computer Science at <a href="https://see.tongji.edu.cn/index.htm">CAD Research Center, Tongji University</a>.
          <br><br>
          <a href="javascript:toggleblock(&#39;old_news&#39;)"><div class="button-13" role="button">show more</div></a>
          <div id="old_news" style="display: none;">
            <br><br>
            Before that, I received my B.Sc degree in Computing Science and Technology from <a href="https://www.swjtu.edu.cn/">Department of Computer Science and Artificial Intelligence, Southwest Jiaotong University</a> in 2022.
            <br><br>
            I was born on Oct 10th, 2000 in <a href="https://en.wikipedia.org/wiki/Dengfeng">Dengfeng</a>, China, which is home to various religious institutions and famous temples and located at the foot of the Mount Song, one of the most sacred mountains in China.
            <br><br>
            I alse took many Biology & Chemistry courses during my initial 2 years in University. 
            <br><br>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:0px;width:100%;vertical-align:middle">
                <heading>Research interests</heading>
              </td>
              </tr>
            </tbody></table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <p>My research focuses on <strong>3D Vision</strong>, including neural rendering, world model, and related technologies. I aim to leverage sophisticated 3D assets to construct immersive synthetic environments, which I envision as foundational tools for advancing AR/VR systems and robotics applications.</p>
              <p>If you find any research interests overlap‚Äîwhether in 3D vision, synthetic data, or AI-driven simulation‚Äîplease don't hesitate to contact me via email. I welcome opportunities for collaboration and am excited to explore shared ideas or projects!
              </p>
              </tr>
            </tbody></table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:0px;width:100%;vertical-align:middle">
                <heading>Current and Past Affiliations</heading>
              </td>
              </tr>
            </tbody></table>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15"><tbody>
              <div class="icon-container">
                <a href="https://www.baai.ac.cn/"><img src="images/baai_logo.png" alt="BAAI" loading="lazy"></a>
                <a href="https://www.noematrix.ai/"><img src="images/noematrix_logo.png" alt="NoemaTrix" loading="lazy"></a>
                <a href="https://www.mi.com/cyberone"><img src="images/mi_logo.png" alt="Xiaomi CyberOne" style="height: 80px;" loading="lazy"></a>
                <a href="https://en.megvii.com/"><img src="images/megvii_logo.png" alt="Megvii" loading="lazy"></a>
                <a href="https://air.tsinghua.edu.cn/"><img src="images/air_discover.png" alt="AIR Tsinghua" loading="lazy"></a>
                <a href="https://see.tongji.edu.cn/index.htm"><img src="images/tj.png" alt="Tongji University" loading="lazy"></a>
                <a href="https://www.swjtu.edu.cn/"><img src="images/swjtu.png" alt="SWJTU" loading="lazy"></a>
              </div>
            </tbody></table>
          </div>
          </td>
      </tr>
    </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Misc</h2>
                <div class="misc-container">
                  <div class="misc-grid">
                    <div class="misc-category">
                      <sub_heading>Music üé∂</sub_heading>
                      <li>Piano üéπ (Grade 10 certification from <a href="https://www.shcmusic.edu.cn/main.htm">Shanghai Conservatory of Music</a>)</li>
                    </div>
                    <div class="misc-category">
                      <sub_heading>Sports üèÉ‚Äç‚ôÇÔ∏è</sub_heading>
                      <li>BasketballüèÄ</li>
                      <li>Badmintonüè∏</li>
                      <li>Swimming üèä‚Äç</li>
                      <li>Flying Discü•è</li>
                    </div>
                    <div class="misc-category">
                      <sub_heading>Language üí¨</sub_heading>
                      <li>‰∏≠Êñá üá®üá≥</li>
                      <li>English üá∫üá∏</li>
                      <li>Êó•Êú¨Ë™û üáØüáµ (learning)</li>
                      <li>Fran√ßais üá´üá∑ (learning)</li>
                    </div>
                    <div class="misc-category">
                      <sub_heading>Others üí°</sub_heading>
                      <li><a href="GS_Guangfulin/index.html">Guangfulin</a></li>
                    </div>
                  </div>
                </div>
              </td>
            </tr>
          </tbody></table>

    <div class="footer-info">
      <div class="footer-content">
        <div class="visitor-map">
          <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=n&d=ccCu5-uOBoVcvpE3u-pG7b3M7VWrbHepzobmvjKerJg&co=ffffff&ct=808080&cmo=3acc3a&cmn=ff5353'></script>
          <noscript>
            <a href="https://clustrmaps.com/site/1c8x4" title="Visit tracker">
              <img src="//www.clustrmaps.com/map_v2.png?cl=080808&w=300&t=n&d=ccCu5-uOBoVcvpE3u-pG7b3M7VWrbHepzobmvjKerJg&co=ffffff&ct=808080&cmo=3acc3a&cmn=ff5353" />
            </a>
          </noscript>
        </div>
        <div class="footer-bottom">
          <span class="copyright">Copyright ¬© Nan Wang 2024-2025</span>
          <span class="separator">‚Ä¢</span>
          <span class="last-updated">Last updated: 2025/06/10</span>
        </div>
      </div>
    </div>
</td>
</tr>
</table>
</div>
</body>
</html>
